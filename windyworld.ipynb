{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windyworld = [\n",
    "    ['_', '_', '_', '_', '_', '_', 'X', 'X'],\n",
    "    ['_', '_', '_', '_', '_', '_', 'X', 'X'],\n",
    "    ['_', '_', '_', 'X', '_', '_', 'X', 'X'],\n",
    "    ['_', '_', '_', 'X', '_', '_', 'X', 'X'],\n",
    "    ['_', '_', '_', '_', '_', '_', 'X', 'X'],\n",
    "    ['_', '_', '_', '_', '_', '_', 'X', 'X'],\n",
    "    ['_', '_', 'X', '_', 'X', '_', '_', '1'],\n",
    "    ['_', '_', 'X', '_', 'X', '_', '_', '_']\n",
    "]\n",
    "wind = ['v', '', 'v', '^', '', 'v', '^', '']\n",
    "\n",
    "DISCOUNT = .9\n",
    "LEARNING_RATE = .1\n",
    "CONVERGENCE_THRESHOLD = .001\n",
    "\n",
    "\n",
    "# Q-Learning ONLY\n",
    "def greedy_policy(q, player_X, player_Y):\n",
    "\n",
    "    max_q = max(q[player_Y][player_X].values())\n",
    "    max_actions = [action for action, value in q[player_Y][player_X].items() if value == max_q]\n",
    "    return random.choice(max_actions)\n",
    "\n",
    "\n",
    "def epsilon_greedy_policy(q, player_X, player_Y, epsilon=0.1):\n",
    "\n",
    "    if random.random() < epsilon:\n",
    "        return random.choice(['N', 'E', 'S', 'W'])\n",
    "    else:\n",
    "        max_q = max(q[player_Y][player_X].values())\n",
    "        max_actions = [action for action, value in q[player_Y][player_X].items() if value == max_q]\n",
    "        return random.choice(max_actions)\n",
    "    \n",
    "\n",
    "def take_a(windyworld, wind, a, player_X, player_Y):\n",
    "\n",
    "    direction_map = {\n",
    "        'N': (0, -1),  # Move North (decrease Y)\n",
    "        'S': (0, 1),   # Move South (increase Y)\n",
    "        'E': (1, 0),   # Move East (increase X)\n",
    "        'W': (-1, 0),  # Move West (decrease X)\n",
    "    }\n",
    "\n",
    "    delta_X, delta_Y = direction_map[a]\n",
    "    new_X = player_X + delta_X\n",
    "    new_Y = player_Y + delta_Y\n",
    "\n",
    "    # Check if the initial movement is within bounds\n",
    "    if 0 <= new_X < len(windyworld[0]) and 0 <= new_Y < len(windyworld):\n",
    "        wind_map = {\n",
    "            '': 0,   # No wind\n",
    "            '^': -1, # Upward wind\n",
    "            'v': 1   # Downward wind\n",
    "        }\n",
    "        new_Y_wind = new_Y + wind_map.get(wind[new_Y], 0)\n",
    "        if 0 <= new_Y_wind < len(windyworld):\n",
    "            return new_X, new_Y_wind\n",
    "\n",
    "    return player_X, player_Y\n",
    "\n",
    "\n",
    "def observe_r(windyworld, player_X, player_Y):\n",
    "\n",
    "    reward_map = {\n",
    "        '1': 1000,\n",
    "        '_': -1,\n",
    "        'X': -10,\n",
    "    }\n",
    "    return reward_map[windyworld[player_Y][player_X]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q_learning is not SARSA with greedy, there are key differences:\n",
    "\n",
    "SARSA evaluates S based on S' (given A) and A' selected from epsilon-greedy and goes along that path.\n",
    "Updates for Q values are based on current (and possibly non optimal) state path.\n",
    "\n",
    "Q_learning evaluates S based on S' (given A) and A' selected from greedy, but may not follow that exact path.\n",
    "Updates for Q values are based on best (and optimal, but possibly not current) state path. \n",
    "'''\n",
    "def Q_learning(windyworld, wind, lr=LEARNING_RATE, d=DISCOUNT, ct=CONVERGENCE_THRESHOLD, min_episode_count=1000):\n",
    "\n",
    "    q = [[{'N': 0, 'E': 0, 'S': 0, 'W': 0} for _ in r] for r in windyworld]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mentzerQA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
